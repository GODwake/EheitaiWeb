# **EheitaiWeb**

这个项目一开始是

有一天我闲着太无聊,准备开始研究一些什么新鲜玩意

刚好有一朋友来和我聊py的爬虫,爬虫这东西不错啊,我也想搞一个

于是想了一下爬虫框架图

![](https://github.com/XHXJ/EheitaiWeb/blob/master/spingboot_ehentai_web/img/%E7%88%AC%E8%99%AB.bmp)



**用框架就用SpingBoot+SpingData+hibernate+jpa+mysql**

利用多线程爬虫,爬取大量数据存入rieds中,使用连接池,每次爬取都是不同的IP.对页面进行4层抓取,最后获得想要的图片地址.

**这里为什么要使用MQ消息中间件?**

因为爬取过程中我发现这个网站反爬虫做得很充分,不仅需要你登录,每次图片地址从你访问开始就是一个新的图片地址,这个地址在30分钟或者更短的时间内就会失效

例:

http://95.211.214.34/lid/65649508/8441eee375913b85b88be57acf46c45b07b1107c-1557110-1920-2645-png/c5a27ea52aac15875ebcd81748dd387d841db78c-203930-1280-1763-jpg/1280/jgn6dmy98c2/0003.jpg

http://94.100.18.172/lid/65649508/8441eee375913b85b88be57acf46c45b07b1107c-1557110-1920-2645-png/c5a27ea52aac15875ebcd81748dd387d841db78c-203930-1280-1763-jpg/1280/jgn6dmy98c2/0003.jpg

请注意该地址ip地址不同,也就说每一次访问可能会获得和上一次结果完全不同的图片地址,并且这个地址随时可能会失效.

除了本身自带失效外,因为该网站服务器在国外,还必须考虑国内网络抓取丢包,数据丢失问题.所以必须用代理池进行爬取.

所以必须用MQ把下载请求分离开,利用一个爬虫服务去爬去网站的页面信息,找到图片下载地址,再把图片下载分给专门处理下载的服务.





刚好没见过java的爬虫,自己研究研究也当提升一下技能了.

项目特点:

	采用代理池,线程池,每次HttpClient请求都是不同的IP地址;
	爬取网站在国外,需要登录并经过四层爬取,自动处理异常连接,
	代理服务器黑名单,自动记录无法爬取的代理服务器并且记录,下次爬取时不采用该服务器.
	能做到精确的爬取每一条数据,并且不重复;
	爬虫进程和下载进程互不影响,独立运行.
	使用ActiveMQ作为中间件通信，为避免爬取数据量过大,下载进程因宽带峰值等原因报错,采用MQ来进行削峰处理;
	使用了多线程轮询算法,由多台稳定的代理服务器提供图片下载.
	通过定时任务,监控mysql中总爬取的数量,数据是否重复,是否爬取完成
	负责对系统的优化、重构，提升系统的性能、稳定性以及可靠性。




说干就干:

开发起来也简单,可以少写写sql语句,这个小爬虫,也要不了多少逻辑,随便搞搞,上个redis做爬取的数据持久化.





直到今天总算是把整个爬虫核心搞定了.等想到啥的时候再写点吧
